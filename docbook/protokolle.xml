<?xml version="1.0" encoding="ISO-8859-1"?>
<chapter id="kapitel-protokolle" lang="de" revision="$Revision: 1.5 $">
  <!--% Copyright (c) 2006 - Stefan Wintermeyer <sw@amooma.de>
% Permission is granted to copy, distribute and/or modify this document
% under the terms of the GNU Free Documentation License, Version 1.2
% or any later version published by the Free Software Foundation;
% with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
% Texts. A copy of the license is included in the section entitled "GNU
% Free Documentation License".
% Asterisk training and consulting is offered at http://www.amooma.de-->

  <title>Protokolle</title>

  <section id="protokolle-einleitung">
    <title>Einleitung</title>

    <para>In diesem Kapitel geht es um die Technik den einzelnen Sprachpakete
    von A nach B zu bekommen. Dies wird von erschiedenen Protokollen
    geleistet. Diese Protokolle setzen aber wiederrum auf verschiedene
    Netzwerkprotokolle (TCP und UDP) auf. Um verschiedene Probleme zu
    verstehen, muss man ein grundlegendes Verständnis für diese
    Netzwerkprotokolle haben. Deshalb werden Sie hier erklärt. Allerdings kann
    man alle normalen Arbeiten auch ganz gut ohne ein entsprechendes
    Verständnis machen. Dieses Kapitel ist also eher als Nachschlagewerk für
    den Fall der Fälle gedacht.</para>
  </section>

  <section>
    <title>Netzwerkprotokolle</title>

    <para>Da es recht wenig Sinn macht das Rad immer wieder neu zu erfinden,
    sind die zwei folgenden Abschnitte über TCP und UDP in großen Teilen an
    die beiden Wikipedia-Artikel zu diesem Thema<footnote>
        <para>Siehe <ulink
        url="http://de.wikipedia.org/wiki/Transmission_Control_Protocol"><citetitle>http://de.wikipedia.org/wiki/Transmission_Control_Protocol</citetitle></ulink>
        und <ulink
        url="http://de.wikipedia.org/wiki/User_Datagram_Protocol"><citetitle>http://de.wikipedia.org/wiki/User_Datagram_Protocol</citetitle></ulink></para>
      </footnote> angelehnt.</para>

    <para>Für alle Ungedultigen: TCP ist ein Protokoll, das sicherstellt das
    die gesamte Information auch beim Empfänger ankommt. Das wird durch einen
    relativ grossen Overhead realisiert. UDP schickt einfach plump alles raus
    und hofft darauf, das es auch beim Empfänger ankommt. Bei einem normalen
    VoIP Anruf wird die initiale Verbindung über TCP hergestellt. Die reinen
    Sprachdaten aber mit UDP übertragen. Denn für ein Telefonat ist Quantität
    wichtiger als Qualität.</para>

    <section id="tcp">
      <title>Transmission Control Protocol (TCP)</title>

      <para>Das Transmission Control Protocol (TCP) ist eine Vereinbarung
      (Protokoll) darüber, auf welche Art und Weise Daten zwischen Computern
      ausgetauscht werden sollen. Alle Betriebssysteme moderner Computer
      beherrschen TCP und nutzen es für den Datenaustausch mit anderen
      Rechnern. Das Protokoll ist ein zuverlässiges, verbindungsorientiertes
      Transportprotokoll in Computernetzwerken. Es ist Teil der
      Internetprotokollfamilie, der Grundlage des Internets. Entwickelt wurde
      TCP von Robert E. Kahn und Vinton G. Cerf. Ihre Forschungsarbeit, die
      sie im Jahre 1973 begannen, dauerte mehrere Jahre. Die erste
      Standardisierung von TCP erfolgte deshalb erst im Jahre 1981 als RFC
      793. Danach gab es viele Erweiterungen, die bis heute in neuen RFCs,
      einer Reihe von technischen und organisatorischen Dokumenten zum
      Internet, spezifiziert werden und alle zu TCP gehören. Im Unterschied
      zum verbindungslosen UDP (User Datagram Protocol) stellt TCP einen
      virtuellen Kanal zwischen zwei Endpunkten einer Netzwerkverbindung
      (Sockets) her. Auf diesem Kanal können in beide Richtungen Daten
      übertragen werden. TCP setzt in den meisten Fällen auf das IP
      (Internet-Protokoll) auf, weshalb häufig (und oft nicht ganz korrekt)
      auch vom TCP/IP-Protokoll die Rede ist. Es ist in Schicht
      4 des OSI-Referenzmodells angesiedelt. Aufgrund seiner vielen angenehmen
      Eigenschaften (Datenverluste werden erkannt und automatisch behoben,
      Datenübertragung ist in beiden Richtungen möglich, Netzwerküberlastung
      wird verhindert usw.) ist TCP ein sehr weit verbreitetes Protokoll zur
      Datenübertragung. Beispielsweise wird TCP als (fast) ausschließliches
      Transportmedium für das WWW, E-Mail, Daten in Peer-to-Peer-Netzwerken
      und viele andere populäre Netzwerkdienste verwendet.</para>

      <section id="tcp-allgemein">
        <title>Allgemeines</title>

        <para>TCP ist im Prinzip eine Ende-zu-Ende-Verbindung in Vollduplex,
        welche die Übertragung der Informationen in beide Richtungen zu
        gleicher Zeit zulässt. Diese Verbindung kann in zwei
        Halbduplexverbindungen, bei denen Informationen in beide Richtungen
        (allerdings nicht gleichzeitig) fließen können, eingeteilt werden. Die
        Daten in Gegenrichtung können dabei zusätzliche
        Steuerungsinformationen enthalten. Die Verwaltung (management) dieser
        Verbindung sowie die Datenübertragung werden von der TCP-Software
        übernommen. Die TCP-Software ist eine Funktionssammlung und (je nach
        Betriebssystem unterschiedlich) bei Linux auch im Betriebssystemkern,
        dem Linux-Kernel, angesiedelt. Anwendungen, die diese Software häufig
        nutzen, sind zum Beispiel Webbrowser und Webserver. Jede
        TCP-Verbindung wird eindeutig durch zwei Endpunkte identifiziert. Ein
        Endpunkt stellt ein geordnetes Paar dar, bestehend aus IP-Adresse und
        Port. Ein solches Paar bildet eine bi-direktionale
        Software-Schnittstelle und wird auch als Socket bezeichnet. Mit Hilfe
        der IP-Adressen werden die an der Verbindung beteiligten Rechner
        identifiziert; mit Hilfe der Ports werden dann auf den beiden
        beteiligten Rechnern die beiden miteinander kommunizierenden Programme
        identifiziert. Durch die Verwendung von Portnummern auf beiden Seiten
        der Verbindung ist es beispielsweise möglich, dass ein Webserver auf
        einem Port (normalerweise Port 80) gleichzeitig mehrere Verbindungen
        zu einem anderen Rechner geöffnet haben kann. Ports sind 16-Bit-Zahlen
        (Portnummern) und reichen von 0 bis 65535. Ports von 0 bis 1023 sind
        reserviert (englisch: well known ports[1]) und werden von der IANA
        vergeben, z. B. ist Port 80 für das im WWW verwendete HTTP-Protokoll
        reserviert. Allerdings ist das Benutzen der vordefinierten Ports nicht
        bindend. So kann jeder Administrator beispielsweise einen FTP-Server
        (normalerweise Port 21) auch auf einem beliebigen anderen Port laufen
        lassen.</para>
      </section>

      <section id="tcp-verbindungsaufbau">
        <title>Verbindungsaufbau und -abbau</title>

        <para>Ein Webserver, der seinen Dienst anbietet, generiert einen
        Endpunkt mit dem Port und seiner Adresse. Dies wird als passive open
        oder auch als listen bezeichnet. Will ein Client eine Verbindung
        aufbauen, generiert er einen eigenen Endpunkt aus seiner
        Rechneradresse und einer noch freien Portnummer. Mit Hilfe eines ihm
        bekannten Ports und der Adresse des Servers kann dann eine Verbindung
        aufgebaut werden. Während der Datenübertragungsphase (active open)
        sind die Rollen von Client und Server (aus TCP-Sicht) vollkommen
        symmetrisch. Insbesondere kann jeder der beiden beteiligten Rechner
        einen Verbindungsabbau einleiten. Während des Abbaus kann die
        Gegenseite noch Daten übertragen, die Verbindung kann also halb-offen
        sein.</para>
      </section>

      <section id="tcp-drei-wege-handshake">
        <title>Der Drei-Wege-Handshake</title>

        <para>ist die Bezeichnung für ein bestimmtes Verfahren, um eine in
        Bezug auf Übertragungsverluste sichere Datenübertragung zwischen zwei
        Instanzen zu ermöglichen. Obwohl überwiegend in der Netzwerktechnik
        verwendet, ist der Drei-Wege-Handshake nicht auf diese
        beschränkt.</para>

        <section>
          <title>Verbindungsaufbau</title>

          <para>Beim Aufbau einer TCP-Verbindung kommt der sogenannte
          Drei-Wege-Handshake zum Einsatz. Der Rechner, der die Verbindung
          aufbauen will, sendet dem anderen ein SYN-Paket (von engl.
          synchronize) mit einer Sequenznummer x. Die Sequenznummern sind
          dabei für die Sicherstellung einer vollständigen Übertragung in der
          richtigen Reihenfolge und ohne Duplikate wichtig. Es handelt sich
          also um ein Paket, dessen SYN-Bit im Paketkopf gesetzt ist (siehe
          TCP-Header). Die Start-Sequenznummer ist eine beliebige Zahl, deren
          Generierung von der jeweiligen TCP-Implementierung abhängig ist. Sie
          sollte jedoch möglichst zufällig sein, um Sicherheitsrisiken zu
          vermeiden [2]. Die Gegenstelle (siehe Skizze) empfängt das Paket und
          sendet in einem eigenen SYN-Paket im Gegenzug ihre
          Start-Sequenznummer y (die ebenfalls beliebig und unabhängig von der
          Start-Sequenznummer der Gegenstelle ist). Zugleich bestätigt sie den
          Erhalt des ersten SYN-Pakets, indem sie die Sequenznummer x um eins
          erhöht und im ACK-Teil (von engl. acknowledgment = Bestätigung) des
          Headers zurückschickt. Der Client bestätigt zuletzt den Erhalt des
          SYN/ACK-Pakets durch das Senden eines eigenen ACK-Pakets mit der
          Sequenznummer y+1. Dieser Vorgang wird auch als Forward
          Acknowledgement bezeichnet. Außerdem sendet der Client den
          Wert x+1 aus Sicherheitsgründen ebenso zurück. Dieses ACK-Segment
          erhält der Server, das ACK-Segment ist durch das gesetzte ACK-Flag
          gekennzeichnet. Die Verbindung ist damit aufgebaut. 1. SYN-SENT
          &rarr; &lt;SEQ=100&gt;&lt;CTL=SYN&gt; &rarr; SYN-RECEIVED 2.
          SYN/ACK-RECEIVED &larr;
          &lt;SEQ=300&gt;&lt;ACK=101&gt;&lt;CTL=SYN,ACK&gt; &larr;
          SYN/ACK-SENT 3. ACK-SENT &rarr;
          &lt;SEQ=101&gt;&lt;ACK=301&gt;&lt;CTL=ACK&gt; &rarr;
          ESTABLISHED</para>
        </section>

        <section>
          <title>Verbindungsabbau</title>

          <para>Der geregelte Verbindungsabbau erfolgt ähnlich. Statt des
          SYN-Bits kommt das FIN-Bit (von engl. finish = Ende, Abschluss) zum
          Einsatz, welches anzeigt, dass keine Daten mehr vom Sender kommen.
          Der Erhalt des Pakets wird wiederum mittels ACK bestätigt. Der
          Empfänger des FIN-Pakets sendet zuletzt seinerseits ein FIN-Paket,
          das ihm ebenfalls bestätigt wird. Obwohl eigentlich vier Wege
          genutzt werden, handelt es sich beim Verbindungsabbau auch um einen
          Drei-Wege-Handshake, da die ACK- und FIN-Operationen vom Server zum
          Client als ein Weg gewertet werden. Zudem ist ein verkürztes
          Verfahren möglich, bei dem FIN und ACK genau wie beim
          Verbindungsaufbau im selben Paket untergebracht werden. Die maximum
          segment lifetime (MSL) ist die maximale Zeit, die ein Segment im
          Netzwerk verbringen kann, bevor es verworfen wird. Nach dem Senden
          des letzten ACKs wechselt der Client in einen zwei MSL andauernden
          Wartezustand (Waitstate), in dem alle verspäteten Segmente verworfen
          werden. Dadurch wird sichergestellt, dass keine verspäteten Segmente
          als Teil einer neuen Verbindung fehlinterpretiert werden. Außerdem
          wird eine korrekte Verbindungsterminierung sichergestellt. Geht ACK
          y+1 verloren, läuft beim Server der Timer ab, und das LAST_ACK
          Segment wird erneut übertragen.</para>
        </section>
      </section>

      <section id="tcp-header">
        <title>Aufbau des TCP-Headers</title>

        <para>Das TCP-Segment besteht immer aus zwei Teilen &ndash; dem Header
        und der Nutzlast (Payload). Die Nutzlast enthält die zu übertragenden
        Daten, die wiederum Protokollinformationen der Anwendungsschicht wie
        HTTP oder FTP entsprechen können. Der Header enthält für die
        Kommunikation erforderliche Daten sowie das Dateiformat beschreibende
        Information. Die Werte werden in network byte order (big endian)
        angegeben.</para>

        <para></para>

        <mediaobject>
          <imageobject>
            <imagedata fileref="bilder/tcp_header.png" />
          </imageobject>
        </mediaobject>
      </section>

      <section id="tcp-datenuebertragung">
        <title> Datenübertragung</title>

        <para></para>

        <section>
          <title>TCP- / IP-Paket-Größe</title>

          <para>Ein TCP-Segment hat typischerweise eine Größe von 1500 Bytes.
          Es darf nur so groß sein, dass es in die darunter liegende
          Übertragungsschicht passt, das Internetprotokoll IP. Das IP-Paket
          ist theoretisch bis 65535 Bytes (64 kiB) spezifiziert, wird aber
          selbst meist über Ethernet übertragen, und dort ist die Rahmengröße
          auf 1500 Bytes festgelegt. TCP und IP Protokoll definieren jeweils
          einen Header von 20 Bytes Größe. Für die Nutzdaten bleiben in einem
          TCP/IP-Paket also 1460 Bytes übrig. Da die meisten
          Internet-Anschlüsse DSL verwenden, gibt es dort noch das
          Point-to-Point Protocol (PPP) zwischen IP und Ethernet, was nochmal
          8 Bytes für den PPP-Rahmen kostet. Dem TCP/IP-Paket verbleiben im
          Ethernet-Rahmen nur 1492 Bytes MTU, die Nutzdaten reduzieren sich
          auf insgesamt 1452 Bytes MSS. Dies entspricht einer Auslastung von
          96,8 %.</para>
        </section>

        <section>
          <title>Aufteilen der Anwendungsdaten auf TCP- / IP-Pakete</title>

          <para>Empfänger und Sender einigen sich vor dem Datenaustausch über
          das Options-Feld auf die Größe der MSS. Die Anwendung, die Daten
          versenden möchte, beispielsweise ein Webserver, legt zum Beispiel
          einen 10 Kilobyte großen Datenblock im Puffer ab. Um beispielsweise
          mit einem 1460 Byte großen Nutzdatenfeld 10 Kilobyte Daten zu
          versenden, teilt man die Daten auf mehrere Pakete auf, fügt einen
          TCP-Header hinzu und versendet die TCP-Segmente. Dieser Vorgang wird
          Segmentierung genannt. Im Puffer ist der Datenblock, dieser wird in
          fünf Segmente aufgeteilt. Jedes Segment erhält durch die
          TCP-Software einen TCP-Header. Drei TCP-Segmente wurden aktuell
          abgeschickt. Diese sind nicht notwendigerweise sortiert, da im
          Internet jedes TCP-Segment einen anderen Weg nehmen und es dadurch
          zu Verzögerungen kommen kann. Damit die TCP-Software im Empfänger
          die Segmente wieder sortieren kann, ist jedes Segment
          nummeriert (die Segmente werden sozusagen
          durchgezählt). Bei der Zuordnung der Segmente wird die Sequenznummer
          herangezogen. Der Empfänger muss diejenigen TCP-Segmente bestätigen,
          die einwandfrei (Prüfsumme ist in Ordnung) angekommen sind.</para>
        </section>
      </section>

      <section id="tcp-flusssteuerung">
        <title> Flusssteuerung</title>

        <para>Da die Anwendung Daten aus dem Puffer liest, ändert sich der
        Füllstand des Puffers ständig. Deshalb ist es notwendig, den
        Datenfluss dem Füllstand entsprechend zu steuern. Dies geschieht mit
        dem Sliding Window und dessen Größe. Den Puffer des Senders erweitern
        wir, wie in Abb. 8 zu sehen, auf 10 Segmente. In der Abb. 8a werden
        gerade die Segmente 1&ndash;5 übertragen. Die Übertragung ist
        vergleichbar mit Abb. 7. Obwohl der Puffer des Empfängers in Abb. 7 am
        Ende voll ist, fordert er mit ACK=7301 die nächsten Daten ab dem Byte
        7301 beim Sender an. Dies hat zur Folge, dass das nächste TCP-Segment
        vom Empfänger nicht mehr verarbeitet werden kann. Ausnahmen sind
        jedoch TCP-Segmente mit gesetztem URG-Flag. Mit dem Window-Feld kann
        er dem Sender mitteilen, dass er keine Daten mehr verschicken soll.
        Dies geschieht, indem er im Window-Feld den Wert Null einträgt (Zero
        Window). Der Wert Null entspricht dem freien Speicherplatz im Puffer.
        Die Anwendung des Empfängers liest nun die Segmente 1&ndash;5 aus dem
        Puffer, womit wieder ein Speicherplatz von 7300 Byte frei ist. Damit
        kann er die restlichen Segmente 6&ndash;10 mit einem TCP-Header, der
        die Werte SEQ=1, ACK=7301 und Window=7300 enthält, beim Sender
        anfordern. Der Sender weiß nun, dass er maximal fünf TCP-Segmente an
        den Empfänger schicken kann, und verschiebt das Window um fünf
        Segmente nach rechts. Die Segmente 6&ndash;10 werden nun alle zusammen
        als Burst verschickt. Kommen alle TCP-Segmente beim Empfänger an, so
        quittiert er sie mit SEQ=1 und ACK=14601 und fordert die nächsten
        Daten an. Silly Window Syndrome: Der Empfänger sendet ein Zero Window
        an den Sender, da sein Puffer voll ist. Die Anwendung beim Empfänger
        liest allerdings nur zwei Byte aus dem Puffer. Der Empfänger schickt
        einen TCP-Header mit Window=2 (Window Update) an den Sender und
        fordert gleichzeitig die zwei Byte an. Der Sender kommt der
        Aufforderung nach und schickt die zwei Byte in einem 42 Byte großen
        Paket (mit IP-Header und TCP-Header) an den Empfänger. Damit ist der
        Puffer des Empfängers wieder voll, und er schickt wieder ein Zero
        Window an den Sender. Die Anwendung liest jetzt zum Beispiel hundert
        Byte aus dem Puffer. Der Empfänger schickt wieder einen TCP-Header mit
        einem kleinen Window-Wert an den Sender. Dieses Spiel setzt sich immer
        wieder fort und verschwendet Bandbreite, da nur sehr kleine Pakete
        versandt werden. Clarks Lösung ist, dass der Empfänger ein Zero Window
        senden und so lange mit dem Window Update warten soll, bis die
        Anwendung mindestens die maximale Segmentgröße (maximum segment size,
        in unseren bisherigen Beispielen 1460 Byte) aus dem Puffer gelesen hat
        oder der Puffer halbleer ist. Je nachdem, was zuerst eintritt (Dave
        Clark, 1982). Auch der Sender kann zu kleine Pakete abschicken und
        dadurch Bandbreite verschwenden. Dieser Umstand wird mit dem
        Nagle-Algorithmus beseitigt. Deswegen ergänzt er sich mit Clarks
        Lösung.</para>
      </section>

      <section id="tcp-slow-start">
        <title>Slow-Start</title>

        <para>Zu Beginn einer Datenübertragung dient der
        Slow-Start-Algorithmus zur Bestimmung des congestion window (wörtlich:
        Überlast-Zeitfenster), um einer möglichen Überlastsituation
        vorzubeugen. Man möchte Staus vermeiden, und da die momentane
        Auslastung des Netzes nicht bekannt ist, wird mit zunächst kleinen
        Datenmengen begonnen. Der Algorithmus startet mit einem kleinen
        Zeitfenster von zwei MSS, in dem Datenpakete vom Sender zum Empfänger
        übertragen werden. Der Empfänger sendet nun eine Bestätigung
        (Acknowledgement, ACK) an den Sender zurück. Anschließend wird die
        Größe des congestion window um eine Segmentgröße erhöht. Für jede
        weitere Bestätigung wird dieses wieder um eine Segmentgröße erhöht,
        das Limit ist das vom Empfänger festgelegte Empfangsfenster. Das
        Wachstum des Fensters ist in der Regel exponentiell, also erst
        langsam, dann schnell; insofern kann der historisch bedingte Name
        Slow-Start fälschlicherweise ein langsames Wachstum
        suggerieren.</para>
      </section>

      <section id="tcp-ueberlastkontrolle">
        <title> Überlastkontrolle</title>

        <para>Gehen bei einer bestimmten Fenstergröße Pakete verloren, kann
        das festgestellt werden, wenn der Sender innerhalb einer bestimmten
        Zeit (Timeout) keine Bestätigung (ACK) erhält. Man muss davon
        ausgehen, dass das Paket aufgrund zu hoher Netzlast von einem Router
        im Netz verworfen wurde. Das heißt, der Puffer eines Routers ist
        vollgelaufen; es handelt sich hier sozusagen um einen Stau im Netz. Um
        diesen aufzulösen, müssen alle beteiligten Sender ihre Netzlast
        reduzieren. Wird ein Paketverlust festgestellt, so wählt man die
        Hälfte der noch unbestätigten Daten im Netz als geeignetes Zeitfenster
        für die Datenübertragung zwischen diesem Sender und diesem Empfänger
        über den benutzten Kanal. Das verlorene Paket wird erneut übertragen,
        für jede Bestätigung wird die Sendefenstergröße wieder um eine MSS
        erhöht wie beim Slow-Start. Fast-Retransmit und Fast-Recovery werden
        eingesetzt, um nach einem Paketverlust schneller auf die
        Stau-Situation zu reagieren. Dazu informiert ein Empfänger den Sender,
        wenn Pakete außer der Reihe ankommen und somit dazwischen ein
        Paketverlust vorliegt. Hierfür bestätigt der Empfänger das letzte
        korrekte Paket erneut für jedes weitere ankommende Paket außer der
        Reihe. Man spricht dabei von Dup-Acks (Duplicate acknowledgements).
        Der Sender bemerkt die duplizierten Bestätigungen, und nach dem
        dritten Duplikat sendet er sofort, vor Ablauf des Timers, das
        verlorene Paket erneut. Weil nicht auf den Ablauf des Timers gewartet
        werden muss, heißt das Prinzip Fast Retransmit. Die Dup-Acks sind auch
        Hinweise darauf, dass zwar ein Paketverlust stattfand, aber doch die
        folgenden Pakete angekommen sind. Deshalb wird das Sendefenster nach
        dem Fehler nur halbiert und nicht wie beim Timeout wieder mit
        Slow-Start begonnen. Zusätzlich kann das Sendefenster noch um die
        Anzahl der Dup-Acks erhöht werden, denn jedes steht für ein weiteres
        Paket, welches den Empfänger erreicht hat, wenn auch außer der Reihe.
        Da dadurch nach dem Fehler schneller wieder die volle Sendeleistung
        erreicht wird, nennt man das Prinzip Fast-Recovery (schnelles
        Erholen). Bis zum Erkennen des Paketverlustes wurden noch
        weitere Pakete bis zur Sendefenstergröße übertragen. Der Empfänger
        konnte diese nicht nutzen, weil ein Paket der Serie verlorenging, aber
        er kann sie im Puffer halten. Nach der Neuübertragung des verlorenen
        Pakets durch den Sender bestätigt der Empfänger mittels ACK und einer
        höheren Sequenznummer die nun vollständige Paketfolge. Das erspart dem
        Sender, alle nach dem Paketverlust übertragenen Pakete erneut zu
        übertragen, und er kann sofort mit ganz neuen Paketen fortfahren; man
        nennt das kumuliertes ACK. Selective ACKs werden genutzt, um noch mehr
        Kontrollinformationen über den Datenfluss vom Empfänger an den Sender
        zurückzuschicken. Dabei wird nach einem Paketverlust vom Empfänger im
        TCP-Optionsfeld ein zusätzlicher Header eingefügt, aus welchem der
        Sender genau ersehen kann, welche Pakete bereits angekommen sind und
        welche fehlen (im Gegensatz zu den standardmäßigen kumulativen ACKs
        von TCP). Als bestätigt gelten die Pakete auch weiterhin erst dann,
        wenn der Empfänger dem Sender ein ACK für die Pakete übermittelt
        hat.</para>
      </section>

      <section id="tcp-datenintegritaet">
        <title>Datenintegrität und Zuverlässigkeit </title>

        <para>Im Gegensatz zum verbindungslosen UDP implementiert TCP einen
        bidirektionalen, byte-orientierten, zuverlässigen Datenstrom zwischen
        zwei Endpunkten. Das darunterliegende Protokoll (IP) ist
        paketorientiert, wobei Datenpakete verlorengehen können, in verkehrter
        Reihenfolge ankommen dürfen und sogar doppelt empfangen werden können.
        TCP wurde entwickelt, um mit der Unsicherheit der darunterliegenden
        Schichten umzugehen. Es prüft daher die Integrität der Daten mittels
        der Prüfsumme im Paketkopf und stellt die Reihenfolge durch
        Sequenznummern sicher. Der Sender wiederholt das Senden von Paketen,
        falls keine Bestätigung innerhalb einer bestimmten Zeitspanne
        (Timeout) eintrifft. Die Daten der Pakete werden beim Empfänger in
        einem Puffer in der richtigen Reihenfolge zu einem Datenstrom
        zusammengefügt und doppelte Pakete verworfen. Der Datentransfer kann
        selbstverständlich jederzeit nach dem Aufbau einer
        Verbindung gestört, verzögert oder ganz unterbrochen werden.
        Das Übertragungssystem läuft dann in einen Timeout. Der vorab
        getätigte Verbindungsaufbau stellt also keinerlei
        Gewähr für eine nachfolgende, dauerhaft gesicherte Übertragung
        dar.</para>
      </section>
    </section>

    <section id="udp">
      <title>User Datagram Protocol (UDP)</title>

      <para>Das User Datagram Protocol (Abk. UDP) ist ein minimales,
      verbindungsloses Netzprotokoll, das zur Transportschicht der
      Internetprotokollfamilie gehört. Aufgabe von UDP ist es, Daten, die über
      das Internet übertragen werden, der richtigen Anwendung zukommen zu
      lassen. Die Entwicklung von UDP begann 1977, als man für die Übertragung
      von Sprache ein einfacheres Protokoll benötigte als das bisherige
      verbindungsorientierte TCP. Es wurde ein Protokoll benötigt, das nur für
      die Adressierung zuständig war, ohne die Datenübertragung zu sichern, da
      dies zu Verzögerungen bei der Sprachübertragung führen würde.</para>

      <section id="udp-funktionsweise">
        <title> Funktionsweise</title>

        <para>Um die Daten, die mit UDP versendet werden, dem richtigen
        Programm auf dem Zielrechner zukommen zu lassen, werden bei UDP
        sogenannte Ports verwendet. Dazu wird bei UDP die Portnummer des
        Dienstes mitgesendet, der die Daten erhalten soll. Diese Erweiterung
        der Host-zu-Host- auf eine Prozess-zu-Prozess-Übertragung wird als
        Anwendungsmultiplexen und -demultiplexen bezeichnet.</para>
      </section>

      <section id="udp-eigenschaften">
        <title> Eigenschaften</title>

        <para>UDP stellt einen verbindungslosen, nicht-zuverlässigen
        Übertragungsdienst bereit. Das bedeutet, dass es keine Garantie gibt,
        dass ein einmal gesendetes Paket auch ankommt oder dass Pakete in der
        gleichen Reihenfolge ankommen, in der sie gesendet wurden. Eine
        Anwendung, die UDP nutzt, muss daher gegenüber verloren gegangenen und
        umsortierten Paketen unempfindlich sein oder selbst entsprechende
        Korrekturmaßnahmen beinhalten. Da vor Übertragungsbeginn nicht erst
        eine Verbindung aufgebaut werden muss, können die Hosts schneller mit
        dem Datenaustausch beginnen. Dies fällt vor allem bei Anwendungen ins
        Gewicht, bei denen nur kleine Datenmengen ausgetauscht werden müssen.
        Einfache Frage-Antwort-Protokolle wie das Domain Name System verwenden
        UDP um die Netzwerkbelastung gering zu halten und damit den
        Datendurchsatz zu erhöhen. Ein Drei-Wege-Handshake wie bei TCP für den
        Aufbau der Verbindung würde unnötigen Overhead erzeugen. Daneben
        bietet die ungesicherte Übertragung auch den Vorteil von geringen
        Übertragungsverzögerungsschwankungen: geht bei einer TCP-Verbindung
        ein Paket verloren, so wird es automatisch erneut angefordert. Dies
        braucht Zeit, die Übertragungsdauer kann daher schwanken, was für
        Multimediaanwendungen schlecht ist. Bei VoIP z.B. würde es zu
        plötzlichen Aussetzern kommen bzw. die Wiedergabepuffer müssten größer
        angelegt werden. Bei verbindungslosen Kommunikationsdiensten bringen
        verlorengegangene Pakete dagegen nicht die gesamte Übertragung ins
        Stocken sondern vermindern lediglich die Qualität. UDP übernimmt die
        Eigenschaften der darunterliegenden Netzwerkschicht. Im Falle des
        Internet Protocols IP können Datenpakete maximal 65535 Bytes lang
        sein, wovon der IP-Header und UDP-Header insgesamt mindestens 28 Bytes
        belegen. UDP-Datagramme haben daher maximal 65507 Nutzdatenbytes.
        Solche Pakete werden jedoch von IP fragmentiert übertragen, so dass
        UDP nur bei Datenpaketgrößen bis zu einigen Kilobytes sinnvoll ist. IP
        löscht Pakete etwa bei Übertragungsfehlern oder bei Überlast.
        Datagramme können daher fehlen. Das UDP-Protokoll bietet hierfür keine
        Erkennungs- oder Korrekturmechanismen wie etwa TCP. Im Falle von
        mehreren möglichen Routen zum Ziel kann IP bei Bedarf neue Wege
        wählen. Hierdurch ist es in seltenen Fällen sogar möglich, dass später
        gesendete Daten früher gesendete überholen.</para>
      </section>
    </section>
  </section>

  <section id="definition-channel">
    <title>Channels</title>

    <para>Ein Channel ist die Verbindung zwischen zwei Punkten (in unserem
    Fall sind das meistens menschliche Gesprächsteilnehmer). Es gibt folgende
    Channel-Arten:</para>

    <itemizedlist>
      <listitem>
        <para>Agent</para>

        <para>Ein ACD Agent-Channel</para>
      </listitem>

      <listitem>
        <para>CAPI</para>

        <para>Ein ISDN-Channel</para>
      </listitem>

      <listitem>
        <para>Console</para>

        <para>Ein Linux-Konsolen-Client-Treiber für Soundkarten, die mit OSS
        oder ALSA angesprochen werden können.</para>
      </listitem>

      <listitem>
        <para>H.323</para>

        <para>Ein VoIP-Protokoll</para>
      </listitem>

      <listitem>
        <para>IAX</para>

        <para>Ein VoIP-Protokoll.<note>
            <para>Prinzipiel gibt es zwei Versionen von IAX (1 und 2). Wer
            heute von IAX spricht, meint immer IAX2 (also die Version
            2).</para>
          </note></para>
      </listitem>

      <listitem>
        <para>Local</para>

        <para>Ein Loopback in einen anderen Context</para>
      </listitem>

      <listitem>
        <para>MGCP</para>

        <para>Ein VoIP-Protokoll</para>
      </listitem>

      <listitem>
        <para>mISDN</para>

        <para>Ein ISDN-Channel</para>
      </listitem>

      <listitem>
        <para>NBS</para>

        <para>Network Broadcast Sound</para>
      </listitem>

      <listitem>
        <para>phone</para>

        <para>Linux Telephony Channel</para>
      </listitem>

      <listitem>
        <para>SIP</para>

        <para>Ein VoIP-Protokoll</para>
      </listitem>

      <listitem>
        <para>Skinny</para>

        <para>Ein VoIP-Protokoll</para>
      </listitem>

      <listitem>
        <para>vISDN</para>

        <para>Ein ISDN-Channel</para>
      </listitem>

      <listitem>
        <para>VOFR</para>

        <para>Voice over frame relay Adtran style</para>
      </listitem>

      <listitem>
        <para>VPB</para>

        <para>Verbindung von normalen Telefonanschlüssen mit
        Voicetronix-Karten</para>
      </listitem>

      <listitem>
        <para>Zap</para>

        <para>Verbindung von normalen Telefonanschlüssen mit Digium-Karten.
        Wird aber auch häufig für Karten anderer Hersteller benutzt.</para>
      </listitem>
    </itemizedlist>

    <para>In den meisten Beispielen in diesem Buch wird immer von
    SIP-Verbindungen ausgegangen. Der Grund dafür ist einfach: Zurzeit gibt es
    sehr viel mehr SIP- als z.B. IAX-fähige VoIP-Telefone. In diesem Kapitel
    werden diese zwei wichtigen Protokolle im Einzelnen beschrieben. Wer will,
    kann dieses Kapitel aber überspringen und bei konkreten Fragen zu
    bestimmten Parametern hier nachschlagen.</para>
  </section>

  <section id="peers-users-friends">
    <title>Peers, Users und Friends</title>

    <para>Die Unterscheidung der Begriffe Peer, User und Friend ist in der
    Asterisk-Dokumentation nicht immer leicht verständlich dargestellt und
    wird daher auch teilweise falsch auf manchen Webseiten wiedergegeben. Die
    folgende Tabelle zeigt die jeweiligen Funktionen:</para>

    <informaltable>
      <tgroup cols="3">
        <tbody>
          <row>
            <entry>Asterisk</entry>

            <entry>&lt;=</entry>

            <entry>User</entry>
          </row>

          <row>
            <entry>Asterisk</entry>

            <entry>=&gt;</entry>

            <entry>Peer</entry>
          </row>

          <row>
            <entry>Asterisk</entry>

            <entry>&lt;=&gt;</entry>

            <entry>Friend</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>Ein Peer kann also nur angerufen werden, ein User nur anrufen und
    ein Friend kann beides.<tip>
        <para>In der Praxis wird meistens nur <parameter>Friend</parameter>
        benutzt. Entsprechend muss man sich diese Tabelle nicht einprägen,
        sondern kann sie im Spezialfall nachschlagen.</para>
      </tip></para>
  </section>

  <section id="iax-vs-sip">
    <title>IAX versus SIP</title>

    <para>Fast jeder Asterisk-Administrator muss sich irgendwann einmal die
    Frage stellen, ob er eher auf SIP oder eher auf IAX setzen soll. Die kurze
    Antwort: Wenn IAX möglich ist (also, wenn die Telefone es unterstützen),
    dann sollte IAX benutzt werden. Ansonsten immer SIP. Mark Spencer (der
    Erfinder von Asterisk) hat zu diesem Thema auf einer Asterisk-Mailingliste
    im Jahr 2004 eine ausführlichere Antwort geschrieben (die original
    englische E-Mail finden Sie im <xref
    linkend="anhang-iax-vs-sip" />):</para>

    <screen>Date: Mon, 5 Jul 2004 18:59:52 -0500 (CDT)
From: Mark Spencer &lt;markster@digium.com&gt;

Ich möchte einige Unterschiede zwischen SIP und IAX kurz 
zusammenfassen. Vielleicht hilft Dir das bei der 
Entscheidungsfindung.

1) IAX arbeitet während des Gesprächs unabhängig von der Anzahl 
der Anrufe und des verwendeten Codecs effizienter als RTP. Der 
Vorteil liegt irgendwo zwischen 2400 Kbit/s für einen 
Einzelanruf und der dreifachen Anzahl der Anrufe pro Megabit 
bei G.729, wenn die Messung bei aktiviertem Trunk-Modus auf der 
MAC-Ebene vorgenommen wird.

2) IAX ist nicht ASCII-, sondern datenelementkodiert. Dies macht
Implementierungen wesentlich leichter und zudem robuster 
gegenüber Pufferüberlaufangriffen, da absolut keine Textanalyse 
oder -interpretation erforderlich ist. IAX führt den gesamten 
IP-Stapel, IAX-Stapel, TDM-Schnittstelle, Echokompensation und 
Erzeugung der Anrufer-ID auf 4k Heap und Stack sowie 64k Flash 
aus. Dies veranschaulicht ganz klar die 
Implementierungseffizienz des Entwurfs. Die Größe der 
IAX-Signalpakete ist drastisch geringer als die bei SIP, was 
aber in der Regel nur dann erwähnenswert ist, wenn zahlreiche 
Clients sich häufig registrieren. Allgemein gesprochen ist IAX2 
bei der Kodierung, der Dekodierung und der Überprüfung der Daten 
effizienter. Zudem wäre es für den Autor einer 
IAX-Implementierung extrem schwierig, eine Inkompatibilität mit 
einer anderen Implementierung herzustellen, da für eine 
Interpretation kaum Raum vorhanden ist.

3) IAX weist eine sehr klare Trennung von Schicht 2 und Schicht 
3 auf, d. h. sowohl Signalisierung als auch Tondaten haben 
definierte Zustände, werden robust und in konsistenter Weise 
übertragen, und wenn ein Endpunkt des Anrufs unvermittelt 
verschwindet, dann wird der Anruf auch zeitnah beendet und zwar
auch dann, wenn keine weiteren Signale und/oder Audiodaten 
empfangen werden. Einen solchen Mechanismus weist SIP nicht auf; 
hinzu kommt, dass, was die Signalisierung angeht, die 
Zuverlässigkeit sehr niedrig und schwerfällig ist, weswegen 
zusätzlich zum Kernstandard RF3261 weitere Standards benötigt 
werden.

4) Die einheitlichen Signalisierungs- und Audiopfade von IAX 
gestatten die transparente Navigation von NATs , und der 
Firewall-Administrator muss lediglich einen einzigen Port 
öffnen, um den Einsatz von IAX zu gestatten. Der IAX-Client 
muss für einen korrekten Betrieb überhaupt nichts über das 
Netzwerk wissen, in dem er sich befindet. Anders gesagt: Es kann 
niemals eine durch eine Firewall bedingte Situation auftreten, 
in der IAX einen Anruf aufbauen und dann keine Audiodaten 
übertragen kann (natürlich vorausgesetzt, es ist genügend
Bandbreite vorhanden).

5) Das authentifizierte Übertragungssystem von IAX gestattet 
die Übertragung von Audio- und Rufsteuerdaten über einen 
zwischengeschalteten Server auf eine robuste Weise: Wenn zwei 
Endpunkte einander aus irgendeinem Grund nicht erkennen können, 
wird der Ruf über den Zentralserver gehalten.

6) IAX trennt die Caller-ID vom Authentifizierungsmechanismus 
des Benutzers. SIP verfügt hierzu über keine eindeutige Methode, 
sofern nicht Remote-Party-IDs verwendet werden.

7) SIP ist ein IETF-Standard. Zwar gibt es eine neue 
Dokumentation von Frank Miller, aber IAX ist gegenwärtig noch 
kein veröffentlichter Standard.

8) IAX ermöglicht es einem Endpunkt, die Gültigkeit einer 
Telefonnummer zu überprüfen, damit er weiß, ob die Nummer 
vollständig ist, vollständig sein könnte oder aber zwar 
vollständig ist, aber länger sein könnte. SIP bietet hierfür 
keine vollständige Unterstützung.

9) IAX sendet DTMF stets außerbandig, d. h. es kann keine 
Verwirrung bezüglich der Frage entstehen, welche Methode verwendet 
wird.

10) IAX unterstützt die Übertragung von Sprache und Kontext, was 
in einer Asterisk-Umgebung durchaus sinnvoll ist. Mehr fällt mir 
jetzt im Moment nicht ein.

Mark

PS: Ich nehme mal an, dass SIP trotzdem ein paar Vorteile 
aufweisen muss (andernfalls wären seine Entwickler ja Dummköpfe).

Es bleibt also zu fragen, wie IAX die folgenden Aspekte verwaltet:
1) Bandbreitenanzeige
2) Neue Codecs
3) Erweiterbarkeit
4) Parken von Verbindungen und andere komplexe Szenarien
5) Videotelephonie

Ich habe den Eindruck, dass dies alles in SIP besser geregelt ist.</screen>

    <para>Nachtrag zu dieser E-Mail: IAX ist mittlerweile ein offenes und gut
    dokumentiertes Protokoll.</para>
  </section>

  <xi:include href="sip.xml" xmlns:xi="http://www.w3.org/2001/XInclude" />

  <xi:include href="iax.xml" xmlns:xi="http://www.w3.org/2001/XInclude" />
</chapter>
